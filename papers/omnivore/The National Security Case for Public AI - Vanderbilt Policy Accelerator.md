---
id: 265476a6-81dc-11ef-8936-cbb9d24372ef
title: |
  The National Security Case for Public AI - Vanderbilt Policy Accelerator
author: |
  Flores, Jorge
source: https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2024/09/27201409/VPA-Paper-National-Security-Case-for-AI.pdf
date_saved: 2024-10-03 16:06:41
date_published: 2024-09-27 00:00:00
draft: true
tags: omnivore
---

From [The National Security Case for Public AI - Vanderbilt Policy Accelerator](https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2024/09/27201409/VPA-Paper-National-Security-Case-for-AI.pdf):

> [!quote]
> transformational innovator and enabler of public-interested technological innovation transformational innovator and enabler of public - interested technological innovation where there is an urgent and compelling national interest.60 Finally, to the extent that where there is an urgent and compelling national interest.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

The U.S. Government has historically been a transformational innovator _when there is no commercial interest in doing something_. Going to the moon is not profitable. Nuclear weapons are not profitable (because it's so highly regulated). AI _is_ profitable and transformational because it is a _feature_ of products that are already profitable. To liken the government's role in AI to the government's role in the moon landing is a joke.

So someone (Congress? who?) should just wave their magic wand and make working in government at least as desirable as working in private industry for AI research.

There are so many things wrong with this.

- The government is slow to move because it works by consensus. Do you think AI innovation would happen if it moved at the pace of the slowest thinker?

- What would motivate a smart and ambitious AI practitioner to work in a slow-moving environment, enmired in bureaucracy, where the penalty for underperforming is a lifelong salary with no critical responsibilities? This is a demoralizing environment to work in.

- Pay is an obvious challenge. How can the government justify the highest-paid government employees--who would have to be paid more than the US president to be competitive--be working on nebulous AI initiatives that are in direct competition with private industry?

> [!quote]
> and rights-abusing actions from domestic surveillance of civil rights leaders to bulk and rights - abusing actions from domestic surveillance of civil rights leaders to bulk data collection. For this reason alone, public AI efforts should be accompanied by strict privacy rules and independent oversight to ensure Americans’ rights. But in creating a privacy rules and independent oversight to ensure Americans’ rights . But in creating a public option for AI, lawmakers have the opportunity to advance, rather than diminish, democratic values and establish layers of oversight and transparency, which importantly - and unlike private companies - are democratically accountable. importantly -  and unlike private companies -  are democratically accountabl e.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

> [!quote]
> quite real prospect of a contractor withholding critical products and services if the firm’s leadership has a policy or political difference with the U.S. government.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Citation needed. When has a major tech firm ever done this?

Companies last a lot longer than presidencies. Holding up Elon Musk as an exemplar of AI companies' influence over policy is grossly disingenuous.

> [!quote]
> contracting to private actors still takes a considerable amount of time compared to in - house development and delivery of solutions.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

> [!quote]
> then the U.S. government should be at the cutting edge of AI safety research. And to conduct cutting-edge AI safety research, the federal government needs its own AI conduct cutting - edge AI safety research, the federal government needs its own AI capabilities on which public employees and outside independent non-profit capabilities on which public employees and outside independent non - profit researchers can build frontier models and conduct safety testing. researchers can build frontier models and conduct safety testing.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

The models will be proprietary, so collaboration with private industry will be necessary to actually have a material impact on AI safety to prevent "large-scale destruction."

Developing its own vertically integrated AI safety capabilities means necessarily going head-to-head with the largest AI companies in the world to develop models that can be deeply inspected. This is not tractable, full stop.

The focus should be on building trust and regulating AI safety, which is the path which the government is already on. Developing parallel capabilities to train frontier models just makes no sense here.

> [!quote]
> It is not unrealistic to worry that such commercial ties to adversarial or diplomatically transactional countries could, if enough money or market share was at stake, undermine or at least complicate American firms’ services to the U.S. government.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

I don't disagree with this. There is a concerning amount of "free money" flowing into the US tech sector from nations with checkered human rights records, for example. This is not unique to AI though.

> [!quote]
> Nondiscrimination rules, or neutrality mandates, require that infrastructural providers serve all comers neutrally without favoritism or price discrimination.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

So GSA prices for everyone?

> [!quote]
> we should expect these firms to continue pursuing anticompetitive actions that undermine innovation as they move into the AI space. Robust, independent public AI capacity also allows for more bespoke into the AI space.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This is quite disingenuous, because it implies that these companies' existing businesses and the markets in which they compete are completely transferable to the AI industry.

The AI industry does not even have a clear path to net profitability yet, so how can the authors claim that monopolies or oligopolies will form unless the government steps in?

> [!quote]
> Altman frames the choice as between two futures: “Will it be one in which the United States and allied nations advance a global AI that spreads the technology’s benefits and opens access to it, or an authoritarian one, in which nations or movements that don’t share our values use AI to cement and expand their power?[^265476a6-81dc-11ef-8936-cbb9d24372ef]

> [!quote]
> One can imagine researchers and developers using public AI resources to develop and deploy AI solutions to address thorny problems of poverty and food insecurity, climate change, and disease – and without problems of poverty and food insecurity, climate change, and disease – and without the imperative to commercialize those solutions or achieve a return on the investment of time and money.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Again, these are applications of AI. The majority of the investment required to make a vertically integrated public AI stack is not in developing AI applications to solve public problems!  The majority of the investment is in duplicating the massive infrastructure build-out, operations, and development of models which can be used by applications.

> [!quote]
> dependence by government or critical infrastructure entities (such as utilities or airlines) on sole source providers for f oundational operations services creates national security risk.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

But this _wasn't_ the case where there was a sole-source provider.

- You can't dual-source email service, and there is no top-down mandate that all government agencies use one email service over another. For every hack of an Exchange account, there is a hack of a Gmail account.

- Similarly, not all airlines were affected by Crowdstrike, because not all airlines chose to use it. In fact, the access that Crowdstrike had to cause the failure that it caused was a result of Microsoft opening up kernel access so other companies could compete with Microsoft's own security software. If the argument is that not everyone should use Windows, well, why hasn't the government addressed this by creating its own operating system, or regulating the operating system business? Honest question.

> [!quote]
> More robust federal investment in the infrastructure and human capa city for public AI is needed.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

The government cannot "invest" its human capacity problems away. This is such an absurdly simplistic view.

> [!quote]
> tech companies seek to maximize profits for their shareholders. But the profit motive does not necessarily overlap with the United States’s national security interests or with the public interest.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

They do not necessarily, but they often do. American tech companies require a stable and successful nation to "maximize profits for their shareholders" so acting in the national interest is often aligned with financial incentives.

> [!quote]
> Moreover, if existential risks or emergent properties do materialize, it would likely be better for the first people to encounter and engage with such models to be public sector AI developers and national security professionals, who can be held publicly accountable, rather than corporate engineers and executives with primarily economic ac countable, rather than corporate engineers and executives with primarily economic incentives.45 There are three reasons for this. First, the government would most likely incentives. 45 45 Public accountability would likely move through multiple mechanisms, including political appointees managing risks to the president, congressional oversight, and media scrutiny. There are three reasons for this. First, the government would most likely encounter and engage with any so-called AI “superintelligence” in a closed, classified encounter and engage with any so - called AI “superintelligence” in a closed, classified facility rather than a more open corporate environment.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

There is no "open corporate environment" in which a superintelligence will be developed. The authors clearly have no clue how leading-edge AI development is happening. The security of the facilities training frontier models are at least as comprehensive as classified data centers. To suggest otherwise is ignorant.

> [!quote]
> Nondiscrimination rules ensure a level competitive playing field for entrepreneurs and non-profit, academic, or public sector competitive playing field for entrepreneurs and non - profit, academic, or public sector customers to access critical resources. In the AI context, these rules would apply to customer s to access critical resources.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Doesn't antitrust cover this, since the authors claim that the whole AI industry is monopolistic?

> [!quote]
> The tech platform example is instructive: countless hours and bil lions of dollars have been spent optimizing what videos and advertisements people should see. Far less effort in our age of technological progress has gone toward improving veterans benefits or social welfare programs –  because that’s not where the money i s.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Quite hyperbolic, but fine.

However, this is an application of AI which is at the very tip of the vertically integrated public AI stack that this paper is calling for. Billions of dollars invested in putting eyeballs on ads is not the same as hundreds of billions of dollars invested in building out infrastructure to support these applications.

> [!quote]
> Here, too, it seems that the DOE will rely on some private sector AI infrastructure and partnerships (including cloud, data centers, and likely software designers).[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This implies that private sector partnership is abhorrent to the notion of public AI. I have bad news--the public sector cannot stand on its own and create its own shadow version of what the AI industry has collectively done.

Part of this is because the AI industry itself has benefited tremendously from public-private partnership. The authors here are ignorant of open-source software and the effective public-private partnership that goes into industry, governments, and universities all contributing to a common foundation.

> [!quote]
> Rather, it is simply to say that profit seekers are likely to argue for policies that benefit their shareholders, not the American public, when these two sets of interest s are at odds.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

A reasonable person could argue that a profit seeker could also be president, a congressperson, or any other elected member of the US government at any given time. This is a pretty weak argument when used to argue that the government will do a better job than corporations or startups.

> [!quote]
> At best, big tech companies have a mixed record when it comes to public safety and welfare and democratic practices. The list of inadequate comes to  public safety and welfare and democratic practices.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

The same thing could be said about the government with equal weight and credibility. Any long-lived organization is going to have blemishes; to present this as if it's unique to Big Tech, and therefore relying on Big Tech must not be trusted and government is the only alternative, is disingenuous.

> [!quote]
> onsider Elon Musk’s control of Starlink for example. 29 29 See Henry Farrell and Abraham Newman, What Happens When Tech Bros Run National Security, ,  T IME (Sept. 20, 2023), https://time.com/6315670/big - tech - national - security/ .  Whatever one thinks of Musk’s political views or the war in Ukraine, should one person – or one firm – be able to undermine U.S. government policy with respect to a major conflict simply because they want to?[^265476a6-81dc-11ef-8936-cbb9d24372ef]

I would like to know how this was "undermining" U.S. policy. Does this statement argue that the federal government should be operating its own Starlink? If so, why isn't it?

> [!quote]
> If private companies understand that the government has the ability to develop national and homeland security solutions in-house, they would have to be develop national and homel and security solutions in - house, they would have to be more competitive in their pricing and more sensitive to delivering on time and on budget.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

So the claim here is that private companies are late and over budget because the government lets them?

Show me a case in the history of leadership supercomputing where this was true. Stuff is late because bad bets are made and developing first-of-a-kind technology to solve groundbreaking problems is fundamentally hard and risky.

I feel like the authors want it both ways; they either want to develop in-house alternatives to commodities available on the open market so they aren't fleeced by nefarious subcontractors, or they want to compete directly with a fast-paced global AI industry developing new technologies at unprecedented cost and scale. Which is it?

> [!quote]
> First and foremost, public AI would bolster innovation. As Mariana Mazzucato has shown, the federal government has been an engine of innovation – and particularly shown, the federal government has been an engine of innovation –  and particularly technological innovation - throughout its history.25 Research and development technological innovation -  throughout its history. 25 25 See generally M ARIANA M AZZUCATO ,  T HE E NTREPRENEURIAL S TATE :  D EBUNKING P RIVATE VS . P UBLIC S ECTOR M YTHS (2013); M ARIANA M AZZUCATO ,  T HE M ISSION E CONOMY :  A M OONSHOT G UIDE TO C HANGING C APITALISM (2021 ).  Research and development programs, national missions and industrial policies, and other publicly-resourced and programs, national missions and industrial policies, and other publicly - resourced and often publicly-run programs have led to considerable breakthroughs. We should often publicly - run programs have led to considerable breakthroughs.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

I'd love to hear the long-form version of the argument that the AI industry would move faster if the government was involved.

This is such a broad, nonspecific argument that washes over all the nuanced differences between AI as a societally revolutionary technology and other revolutionary technologies that got off the ground with government support.

> [!quote]
> s. It ensures that national security goals cannot be Even if the public option is limited to public dictated or determined by private actors.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

To claim that anything government-made will be "free from conflicts of interest or the whims of powerful private citizens" is patently absurd given the country's campaign finance regulations and the tendency for some people in power (public or private) to abuse that power for personal profit.

To claim that never happens, which this statement does, undercuts a significant chunk of the whole argument here. It indicates the authors make this argument from an idealized world, not the one in which we live.

> [!quote]
> Second, corporate incentives will likely push in the direction of release without sufficient testing or controls.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Again, the authors have clearly never talked to anyone who is credibly working on AGI. 

A system running a superintelligence will be phenomenally expensive to own and operate. To suggest that any person off the street would be given access to a superintelligence for "impressions" ignores the financial realities of how this will play out.

> [!quote]
> Arguments about tech patriotism in the AI race with China are particularly questionable given that most of the big tech companies operate in China, are dependent on China for production of their hardware, or have consistently attempted to get into Chinese markets (and simply been thwarted by Chinese officials).[^265476a6-81dc-11ef-8936-cbb9d24372ef]

I agree with the sentiment, but I don't think this statement is as true as the authors wish it to be. As relations between the US and China get frostier, companies have a natural incentive to distance themselves.

> [!quote]
> Our current, largely unregulated ecosystem of one GPU manufacturer, three Big Tech cloud curren t, largely unregulated ecosystem of one GPU manufacturer, three Big Tech cloud providers, and a handful of AI labs at or affiliated with Big Tech companies will not provide the AI that the United States needs to safeguard national security and serve the public. Policymakers should redouble their attention on the public’s role in the pu blic.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This seems intentionally hyperbolic.

- Don't tell AMD that there's only one GPU provider.

- Even if there was even competition in the market, what will you do about TSMC? This isn't a one-dimensional issue.

- Don't tell Meta AI that they are affiliated with a cloud provider. Or Anthropic. In fact, OpenAI and Google are the only two AI labs that fit this bill.

> [!quote]
> companies, h[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Doesn't this statement undercut the idea that private industry cannot be trusted to care about AI safety? It didn't take a government to tell these people to create their own firms or to get venture capitalists to fund them. The problem is being addressed exclusively by private industry, and by the same evil Big Tech and VC firms that are treating AI safety as an afterthought.

Regarding "the risk of large-scale destruction," that's not what the testimony says.

> [!quote]
> Some frontier AI companies have already been sued for training their models using massive amounts of copyrighted materials without permission or payment.39 Add to this the fact that the copyrighted materials without permission or payment. 39[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Things rings a little hollow given how much research for the public good gets locked behind the paywalls of journals and major publishers.

As I said above, so many of these points about how Big Tech isn't to be trusted can be turned right back around at the government. These problems are not unique to private sector; they are a function of the way the country and society incentivizes the behavior of people regardless of who employs them.

> [!quote]
> Investing in people with technological expertise has the potential to create a virtuous cycle: a more affordable mission-driven staff would not only build public-interested AI cycle: a more affordable mission - driven staff would not only build public - interested AI systems for a wide variety of public- uses but could also evaluate private sector AI systems for a wide variety of public - uses but could also evaluate private sec tor AI services more accurately and reduce the likelihood that government contracts will suffer from cost and quality problems.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This is one of the dumbest things I've read on this topic, and it stinks of someone who's never worked on both sides of technology. Likening leadership in AI innovation to the rollout of a generic web service like healthcare.gov reflects a complete lack of understanding of how AI, and the specialized expertise it requires, differs from general IT functions.

There is no such thing as "more affordable mission-driven staff" when it comes to AI. Do you think people working at Meta, OpenAI, and other leading AI labs are "affordable?"

I believe in the mission more than most people working in Big Tech, but this claim is patently absurd.

> [!quote]
> When government does need to leverage the private sector, a robust, independent public AI capacity will improve its ability to effectively partner with industry to advance the national interest.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

How? With a magic wand? I don't understand this claim.

> [!quote]
> reliance on outsourcing to contractors and consultants saps the government of knowledge, talented people, and focus on public problems.36 Building this capacity is important: agencies with focus on public problems.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Explain how DOE ASCR and NNSA/SC programs work given this statement.

You cannot apply generic findings from the defense sector and claim it applies to AI when you already have a much more realistic analog in the government already.

> [!quote]
> Third, and relatedly, the government has decades of experience (and is generally quite good at) maintaining security for extremely dangerous materials and generall y quite good at) maintaining security for extremely dangerous materials and sensitive information – from nuclear and cyber weapons to disease samples and state sensitive information –  from nuclear and cyber weapons to disease samples and state secrets. Indeed, this is one reason why these activities are either publicly run and secrets.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Do you think corporations aren't good at keeping secrets too? Show me evidence that the government is _better than industry_ at these things.

The specific cases mentioned here are places where the private sector is not allowed to compete. Of course the government will have a better track record, because nobody else is on the track.

> [!quote]
> Cost - overruns and delivery delays are standard. 33 33 See, e.g., Rose L. Thayer, Delays in military construction have doubled in last 5 years often adding millions of dollars to the cost, watchdog  finds , S TARS &  S TRIPES (Sept. 16, 2024), https://www.stripes.com/theaters/us/2024 - 09 - 16/military - construction - delays - 15199919.html .  ppyy Quality of the output is sometimes a problem.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This is a non sequitur. Is this because of contracting, or is it incidental to contracting?

I don't understand how bringing these capabilities in-house will somehow make the process on-time and under-budget. What are examples of government functions which are handled in-house that are successful and efficient? Jury duty and going to the DMV?

> [!quote]
> irst, the sprint to build public AI would complement – not prevent, preclude, or crowd out – private AI to build public AI would complement – not prevent, preclude, or crowd out –  private AI infrastructure and investment. It would coexist with the private sector and address infrastructure and investment. It would coexist with the private sector and add ress national security challenges and public goods[^265476a6-81dc-11ef-8936-cbb9d24372ef]

There is zero threat that public AI would "crowd out" private AI. And "coexist with" is very hard to distinguish from "compete against, poorly" when it comes to paying smart people to do innovative things that have dual use.

> [!quote]
> Moreover, having serious in - house AI exper tise and capacity will improve federal agencies’ capacity to evaluate private contractors’ AI proposals and products, and in turn, ensure that the government gets the products and services it needs at a fair price. This is one reason why experts have recommended building up federal tech fair price. This is one reason why experts have recom mended building up federal tech capacity and personnel across agencies.37 capacity and personnel across agencies. 37[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Again--wave a magic wand and it will be so.

> [!quote]
> By public AI, we mean two things: publicly - provided, - owned and - operated layers in the AI tech stack, such as cloud in frastructure, data, and model development; and public utility - style regulation of the private AI industry that fosters competition and prevents abuses of power.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

How is "public utility-style regulation" different from the aforementioned "authoritarian" style? Honest question.

What would stop AI innovation from moving to countries that simply do not impose public utility-style regulation that isn't the hyperbolic "authoritarian" government described above?

If space, power, cooling, and money are the only things stopping private AI industry, I can think of several places in the world (that aren't the USA) that could make attractive landing spots. Given the political extremism and volatility in the US, one could reasonably argue that there are _better_ places than the US where such innovation could happen.

Regulation won't work nearly as well when the workforce is remote and the regulations are not part of global societal norms.

> [!quote]
> Of course, the federal government is not perfect either, especially in the national security context. The U.S. government has undertaken its fair share of undemocratic vu.edu/vpa 18[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This started out good and then took a hard turn. Why is public AI the only one that should be accompanied by strict privacy rules? This statement reads like "we should have public AI so that we can regulate data privacy" when the real statement should be "we should regulate data privacy."

> [!quote]
> Even if the system does not replicate all of these pathologies, once national security needs are identified, vu.edu/vpa 16[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Citation needed. This is not true.

> [!quote]
> Without competition or regulation, an AI oligopoly is likely to box out innovative start-ups, lose their innovative regulation, an AI oligopoly is likely to box out innovative start - ups, lose their innovative edge, offer worse quality of service to government clients, and raise costs for the American taxpayer. Regulating market structure to prevent the abuses of monopoly American taxpayer.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

At what level of the stack is "AI oligopoly" being defined here? Or is it all of them?

What in the world is an "innovative start-up" when it comes to building multi-billion dollar data centers?

What is an "innovative start-up" in the context of chipmakers who all rely on TSMC fab capacity to make their chips, and who can design chips from locations around the world?

The problem with the public utility analogy is that public utilities are geographically anchored to their consumers in the US. By comparison, the AI supply chain faces global competition. American AI companies will not "lose their innovative edge" because they're getting fat off of government contracts; they'll lose them because other countries are playing on the same field and can move faster.

> [!quote]
> It is textbook economics that firms facing little competition and no regulation to discipline them will both abuse their power and fail to innovate.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

There is an AI arms race happening right now between a combination of AI startups and large technology firms. How can the authors say that there is "little competition" in one of the most fiercely competitive technology races that private industry has ever seen?

If there is "little competition," why are so many people in the AI business working 60+ hour weeks?

> [!quote]
> It would also ensure a dedicated, resilient, and uncompromised AI capacity that would meaningfully strengthen national security and advance public AI capacity[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Resilient? Will you just wave a magic wand? What is the alternative? Who's making unresilient infrastructure?

What does "uncompromised AI capacity" even mean?

> [!quote]
> In the AI context, structural separations could be placed between chip makers, cloud providers, and model developers[^265476a6-81dc-11ef-8936-cbb9d24372ef]

Is this a real threat? History has shown that being vertically integrated is often a very bad thing; compare Intel, which is vertically integrated in chip design and fab, and NVIDIA, which is not.

The coal and railroad analogy is imperfect because railroads and coal are both independently useful. A data center is not useful unless there are GPUs in it, and a GPU isn't useful unless there is a model to train on it. Again, this stinks of the authors not actually knowing how the supply chain underneath AI models actually works.

> [!quote]
> In short, these regulations would help keep the AI ecosystem healthy for the situations in which contracting out is necessary.[^265476a6-81dc-11ef-8936-cbb9d24372ef]

This is a good place to point out that much of this report is a giant slap in the face to the DOE and NSF supercomputing programs.

These organizations rely heavily on contractors and subcontractors to deliver the closest thing to a national AI infrastructure today. To suggest that they should be absorbed into the federal government--and be even more constrained than they currently are in the choices they can make, the costs they must incur for compliance, and the excess oversight and process that erodes their agility--is completely out of touch with reality.

DOE and NSF have shown that the government does not need to be vertically integrated and own all its own chipmaking, system integration, data centers, and applications to advance science for the public good. Perhaps more than any other single sentence in this report, the tone of this statement makes me question whether it was a good use of my time to even respond to this report, because it is in no way grounded with the decades of success that the government has already had in maintaining technology and infrastructure, largely through public-private partnership, for the national interest.

> [!quote]
> the U.S. Government has historically been a vu.edu/vpa 23[^265476a6-81dc-11ef-8936-cbb9d24372ef]

[^265476a6-81dc-11ef-8936-cbb9d24372ef]: [The National Security Case for Public AI - Vanderbilt Policy Accelerator](https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2024/09/27201409/VPA-Paper-National-Security-Case-for-AI.pdf)